{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Updated_R7_ExternalLab_Questions_Manu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WH1Pr4KQlCh",
        "colab_type": "text"
      },
      "source": [
        "### Build a DNN using Keras with `RELU` and `ADAM`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbvI8LqlQlCl",
        "colab_type": "text"
      },
      "source": [
        "#### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPW-a-qYQlCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "e467f652-9f61-4e05-84ee-add69070011d"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cQBsi5QlCw",
        "colab_type": "text"
      },
      "source": [
        "#### Collect Fashion mnist data from tf.keras.datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWy0oDTr2Kj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f181fa4-c057-4abd-c3c4-1c47fce4731b"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no7aWYZyQlC1",
        "colab_type": "text"
      },
      "source": [
        "#### Change train and test labels into one-hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX6otc4wQlC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert labels to one hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjNrRTdoQlC5",
        "colab_type": "text"
      },
      "source": [
        "#### Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZsYlULqFb1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8aa39708-8039-4a1f-9c9f-325760d5a222"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model1.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBGwTTilQlDD",
        "colab_type": "text"
      },
      "source": [
        "#### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXbfpfOzQlDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hidden layers\n",
        "model1.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
        "\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model1.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "#Dropout layer\n",
        "model1.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I8f5otcQlDJ",
        "colab_type": "text"
      },
      "source": [
        "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZkvKymSd0Sr",
        "colab_type": "code",
        "outputId": "07b46eca-ee30-45a2-a76e-a8a7a2e0ffb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Output layer\n",
        "model1.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model1.summary()\n",
        "#Train the model1\n",
        "model1.fit(x_train,y_train,\n",
        "          validation_data=(x_test,y_test),\n",
        "          epochs=40,\n",
        "          batch_size=32)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "Layer_1 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "Layer_2 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 182,446\n",
            "Trainable params: 180,278\n",
            "Non-trainable params: 2,168\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.5223 - acc: 0.8159 - val_loss: 0.3977 - val_acc: 0.8600\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.4010 - acc: 0.8551 - val_loss: 0.3774 - val_acc: 0.8637\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.3604 - acc: 0.8690 - val_loss: 0.3484 - val_acc: 0.8751\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.3374 - acc: 0.8775 - val_loss: 0.3480 - val_acc: 0.8731\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.3172 - acc: 0.8841 - val_loss: 0.3288 - val_acc: 0.8834\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.3003 - acc: 0.8903 - val_loss: 0.3356 - val_acc: 0.8826\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.2875 - acc: 0.8929 - val_loss: 0.3318 - val_acc: 0.8850\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.2759 - acc: 0.8975 - val_loss: 0.3391 - val_acc: 0.8864\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.2655 - acc: 0.9016 - val_loss: 0.3524 - val_acc: 0.8866\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.2571 - acc: 0.9044 - val_loss: 0.3309 - val_acc: 0.8880\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.2466 - acc: 0.9082 - val_loss: 0.3495 - val_acc: 0.8925\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.2389 - acc: 0.9107 - val_loss: 0.3443 - val_acc: 0.8907\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.2356 - acc: 0.9124 - val_loss: 0.3366 - val_acc: 0.8940\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.2287 - acc: 0.9142 - val_loss: 0.3849 - val_acc: 0.8930\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 10s 168us/sample - loss: 0.2189 - acc: 0.9188 - val_loss: 0.3540 - val_acc: 0.8872\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.2141 - acc: 0.9198 - val_loss: 0.3741 - val_acc: 0.8915\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.2075 - acc: 0.9225 - val_loss: 0.3548 - val_acc: 0.8904\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.2041 - acc: 0.9235 - val_loss: 0.3817 - val_acc: 0.8859\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.2000 - acc: 0.9258 - val_loss: 0.3462 - val_acc: 0.8948\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.1934 - acc: 0.9277 - val_loss: 0.3517 - val_acc: 0.8924\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.1924 - acc: 0.9278 - val_loss: 0.3773 - val_acc: 0.8894\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 10s 164us/sample - loss: 0.1852 - acc: 0.9309 - val_loss: 0.4500 - val_acc: 0.8904\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.1848 - acc: 0.9301 - val_loss: 0.3705 - val_acc: 0.8932\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 10s 165us/sample - loss: 0.1792 - acc: 0.9333 - val_loss: 0.4242 - val_acc: 0.8901\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 11s 188us/sample - loss: 0.1770 - acc: 0.9335 - val_loss: 0.4956 - val_acc: 0.8908\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.1713 - acc: 0.9348 - val_loss: 0.3979 - val_acc: 0.8968\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 10s 165us/sample - loss: 0.1734 - acc: 0.9348 - val_loss: 0.3953 - val_acc: 0.8967\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 10s 168us/sample - loss: 0.1652 - acc: 0.9373 - val_loss: 0.3922 - val_acc: 0.8958\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 11s 185us/sample - loss: 0.1647 - acc: 0.9386 - val_loss: 0.3998 - val_acc: 0.8922\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.1617 - acc: 0.9394 - val_loss: 0.4139 - val_acc: 0.8927\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.1579 - acc: 0.9402 - val_loss: 0.4135 - val_acc: 0.8928\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.1563 - acc: 0.9396 - val_loss: 0.3812 - val_acc: 0.8953\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 9s 150us/sample - loss: 0.1520 - acc: 0.9419 - val_loss: 0.3854 - val_acc: 0.8961\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.1512 - acc: 0.9427 - val_loss: 0.4137 - val_acc: 0.8959\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.1450 - acc: 0.9452 - val_loss: 0.4709 - val_acc: 0.8945\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 9s 152us/sample - loss: 0.1470 - acc: 0.9444 - val_loss: 0.4541 - val_acc: 0.8928\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.1426 - acc: 0.9464 - val_loss: 0.4317 - val_acc: 0.8953\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 9s 152us/sample - loss: 0.1420 - acc: 0.9459 - val_loss: 0.4221 - val_acc: 0.8941\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.1389 - acc: 0.9470 - val_loss: 0.5095 - val_acc: 0.8970\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.1364 - acc: 0.9483 - val_loss: 0.4911 - val_acc: 0.8919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2fc165400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6IH5BKkgaH",
        "colab_type": "code",
        "outputId": "08aa2944-9c28-4538-dea2-468225197675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "model1.save('dnn_2.h5')\n",
        "model1 = tf.keras.models.load_model('dnn_2.h5')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ6u2xtQd91a",
        "colab_type": "code",
        "outputId": "83d23995-6a9b-4a21-ed5c-c4b692095b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "#Train the model1\n",
        "model1.fit(x_train,y_train,\n",
        "          epochs=20,\n",
        "          initial_epoch=10,\n",
        "          validation_data=(x_test,y_test),\n",
        "          batch_size=32)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 11s 190us/sample - loss: 0.1383 - acc: 0.9476 - val_loss: 0.4250 - val_acc: 0.8967\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 12s 195us/sample - loss: 0.1337 - acc: 0.9499 - val_loss: 0.5512 - val_acc: 0.8965\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 12s 197us/sample - loss: 0.1337 - acc: 0.9486 - val_loss: 0.4833 - val_acc: 0.8979\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 11s 181us/sample - loss: 0.1316 - acc: 0.9506 - val_loss: 0.4887 - val_acc: 0.8934\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 11s 179us/sample - loss: 0.1298 - acc: 0.9513 - val_loss: 0.5670 - val_acc: 0.8952\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 11s 178us/sample - loss: 0.1298 - acc: 0.9520 - val_loss: 0.4724 - val_acc: 0.8947\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 11s 179us/sample - loss: 0.1274 - acc: 0.9523 - val_loss: 0.4310 - val_acc: 0.8972\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 11s 186us/sample - loss: 0.1237 - acc: 0.9531 - val_loss: 0.5371 - val_acc: 0.8909\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 12s 197us/sample - loss: 0.1225 - acc: 0.9538 - val_loss: 0.4830 - val_acc: 0.8948\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 11s 180us/sample - loss: 0.1215 - acc: 0.9534 - val_loss: 0.4881 - val_acc: 0.8953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2e7b69c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK1R7ouPksXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RnEHbvzjgSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}